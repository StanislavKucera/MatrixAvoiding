\chapter{Markov chain Monte Carlo}
\label{chap:mcmc}
Our goal to generate $M\in_R\mathcal{M}(\mathcal{P})$ heavily depends on the theory of Markov chains. We only define useful terms and state two important theorems. If you are interested in more details, see \cite{Madras} or \cite{Karlin}.

\section{Markov chains}
\begin{defn}
Let $\mathcal{S}$ be a finite set of states and for every $i,j\in\mathcal{S}$, let $p_{i,j}$ be a prescribed probability of a change of state from $i$ to $j$. Also let $X_0$ be a random variable with values from $\mathcal{S}$. We call a sequence $X_0,X_1,\dots$, where $X_i\in\mathcal{S}$ for every $i$ a \emph{Markov chain} if
$$Pr(X_{t+1}=j|X_t=i)=p_{i,j} \hspace{1cm} (i,j\in\mathcal{S})$$
\end{defn}
\begin{defn}
A Markov chain is said to be \emph{symmetric} if $p_{i,j}=p_{j,i}$ for every pair of states $i$ and $j$.
\end{defn}
\begin{defn}
A Markov chain is \emph{irreducible} if the chain can eventually get from each state to every other state, that is, for every $i,j\in\mathcal{S}$ there exists a $k\geq0$ (depending on $i$ and $j$) such that $Pr(X_k=j|X_0=i)>0$.
\end{defn}
\begin{defn}
Let $p_{i,j}^{(k)}=Pr(X_{t+k}=j|X_t=i)$ denote the $k$-step transition probabilities for $k=0,1,\cdots$ and $i,j\in\mathcal{S}$. An irreducible Markov chain has \emph{period}~$D$ if $D$ is the greatest common divisor of $\{k\geq1|p_{i,i}^{(k)}>0\}$ for some $i\in\mathcal{S}$ (equivalently, for all $i\in S$). A chain is called \emph{aperiodic} if its period is 1. In particular, if an irreducible chain has $p_{i,i}^{(1)}>0$ for some $i$, then it is aperiodic.
\end{defn}

If $X_0,X_1,\dots$ is an irreducible, symmetric and aperiodic Markov chain on state space $\mathcal{S}$ then $\lim\limits_{k\rightarrow\infty}X_k\in_R\mathcal{S}$ independent of the choice of $X_0$.

\section{Markov chain for pattern-avoiding binary matrices}
\label{sect:mmcmc}
To generate a binary matrix $M\in\{0,1\}^{n\times n}$ avoiding patterns in $\mathcal{P}$, we create a Markov chain, whose states space is $\mathcal{M}_n(\mathcal{P})$. After sufficiently many iterations ($m$) of MCMC process we set $M:=X_m\in\mathcal{M}_n(\mathcal{P})$. We always begin with an initial matrix $X_0$ and the process looks like this:
\begin{enumerate}
\item For $i:=1,2,\cdots,m$:
\item \hspace{5mm} Set $X_{i}:=X_{i-1}$.
\item \hspace{5mm} Choose $r\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Choose $c\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Flip the bit at $X_{i}[r,c]$.
\item \hspace{5mm} If $X_{i}$ contains $\mathcal{P}$, flip the bit back.
\end{enumerate}

If the process starts with a matrix $X_0$ that avoids $\mathcal{P}$, then after every step it still avoids $\mathcal{P}$. Note that an iteration does not change the matrix if the condition 6 is satisfied. We need to show the Markov chain we presented meets all the conditions of both theorems:
\subsubsection{Symmetry}
If $i$ and $j$ differ in more that one bit, we will never get one from the other by flipping one bit; therefore, both $p_{i,j}=p_{j,i}=0$. If $i$ and $j$ differ in exactly one bit, we have $p_{i,j}=p_{j,i}=\frac{1}{n^2}$, because we need to change exactly that one bit to succeed. Otherwise, $i=j$ and we have $p_{i,i}=p_{i,i}$.
\subsubsection{Irreducibility}
As the steps go, it is easy to see we can with non-zero probability create any matrix $M_1\in\mathcal{M}_n(\mathcal{P})$ from the zero matrix $0_n=0^{n\times n}$ by choosing the one-entries of $M_1$. When we can get from $0_n$ to $M_2$ by a sequence of flip changes, the reversed sequence is a sequence of steps from $M_2\in\mathcal{M}_n(\mathcal{P})$ to $0_n$. Thus, with non-zero probability we can always reach $M_2$ from $M_1$; therefore, the Markov chain is irreducible.
\subsubsection{Aperiodicity}
The Markov chain is irreducible so it suffices to show that there is an $i$ for which $p_{i,i}>0$. Clearly, there is a matrix for which there is at least one bit that cannot be flipped without creating a pattern (for example the one with the maximum number of one-entries) and this forces $p_{i,i}>0$.