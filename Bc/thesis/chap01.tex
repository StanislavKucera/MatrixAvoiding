\chapter{Markov chain Monte Carlo}
\label{chap:mcmc}
Our goal to generate $M\in_R\mathcal{M}(\mathcal{P})$ heavily depends on the theory of Markov chains. In this work we only define useful terms and state two important theorems. If you are interested in more details, see \cite{Madras}.

\section{Markov chains}
\begin{defn}
We shall consider discrete-time \emph{Markov chain} $X_0,X_l,\dots$, where $X_i\in\mathcal{S}$, for a finite state space $\mathcal{S}$ and every $i$ (number of steps). The $k$-step transition probabilities are:
$$p_{i,j}^{(k)}=Pr(X_{t+k}=j|X_t=i) \hspace{1cm} (i,j\in\mathcal{S})$$
\end{defn}
\begin{defn}
A Markov chain is said to be \emph{symmetric} if $p_{i,j}^{(1)}=p_{j,i}^{(1)}$ for every pair of states $i$ and $j$.
\end{defn}
\begin{defn}
A Markov chain is \emph{irreducible} if the chain can eventually get from each state to every other state, that is, for every $i,j\in\mathcal{S}$ there exists a $k\geq0$ (depending on $i$ and $j$) such that $p_{i,j}^{(k)}>0$.
\end{defn}
\begin{defn}
An irreducible chain has \emph{period} $D$ if $D$ is the greatest common divisor of $\{k\geq1|p_{i,i}^{(k)}>0\}$ for some $i\in\mathcal{S}$ (equivalently, for all $i\in S$). A chain is called \emph{aperiodic} if its period is 1. In particular, if an irreducible chain has $p_{i,i}^{(1)}>0$ for some $i$, then it is aperiodic.
\end{defn}
\begin{thm}
Consider an aperiodic irreducible Markov chain with state space $\mathcal{S}$. For every $i,j\in S$, the limit $\lim_{k\rightarrow\infty}p_{i,j}^{(k)}$) exists and is independent of $i$; call it $\pi_j$. Furthermore, if $\mathcal{S}$ is finite, then
$$\sum\limits_{j\in\mathcal{S}}\pi_j=1\hspace{5mm}\wedge\hspace{5mm}\sum\limits_{i\in\mathcal{S}}\pi_ip_{i,j}^{(1)}=\pi_j$$
for every $j\in\mathcal{S}$. That is, if we write $\pi$ to denote the row vector whose entries are $\pi_i$, then $\pi P=\pi$.
\end{thm}
\begin{thm}
Suppose that an irreducible Markov chain on the finite state space $\mathcal{S}$ is symmetric. Then the equilibrium distribution is uniform on $\mathcal{S}$.
\end{thm}

In other words, the theorems together give us a guarantee that if we choose an irreducible, symmetric and aperiodic Markov chain with state space $\mathcal{S}$ then the probability distribution of $X_i$ converges to uniform distribution on $\mathcal{S}$ independently of the initial state.

\section{Markov chain for pattern-avoiding binary matrices}
\label{sect:mmcmc}
To generate a binary matrix $M\in\{0,1\}^{n\times n}$ avoiding patterns in $\mathcal{P}$, we create a Markov chain, whose states space is $\mathcal{M}_n(\mathcal{P})$. After sufficiently many iterations ($m$) of MCMC process we set $M:=X_m\in\mathcal{M}_n(\mathcal{P})$. We always begin with an initial matrix $X_0$ and the process looks like this:
\begin{enumerate}
\item For $i:=1,2,\cdots,m$:
\item \hspace{5mm} Set $X_{i}:=X_{i-1}$.
\item \hspace{5mm} Choose $r\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Choose $c\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Flip the bit at $X_{i}[r,c]$.
\item \hspace{5mm} If $X_{i}$ contains $\mathcal{P}$, flip the bit back.
\end{enumerate}

If the process starts with a matrix $X_0$ that avoids $\mathcal{P}$, then after every step it still avoids $\mathcal{P}$. Note that an iteration does not change the matrix if the condition 6 is satisfied. We need to show the Markov chain we presented meets all the conditions of both theorems:
\subsubsection{Symmetry}
Imagine a sequence of bits flipping which changes the $i$-th matrix to $j$-th one. The reversed order of the same sequence changes the $j$-th matrix to the $i$-th one.
\subsubsection{Irreducibility}
As the steps go, it is easy to see we can with non-zero probability create any matrix $M\in\mathcal{M}_n(\mathcal{P})$ from the zero matrix $0_n=0^{n\times n}$ by choosing the one-entries of $M$. When we can get from $0_n$ to $M$ by a sequence of flip changes, the reversed sequence is a sequence of steps from any matrix $\in\mathcal{M}_n(\mathcal{P})$ to $0_n$. Thus the Markov chain is irreducible.
\subsubsection{Aperiodicity}
The Markov chain is irreducible so it suffices to show that there is an $i$ for which $p_{i,i}^{(1)}>0$. Clearly there is a matrix for which there is at least one bit that cannot be flipped without creating a pattern and this forces $p_{i,i}^{(1)}>0$.