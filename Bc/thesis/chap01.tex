\chapter{Markov chain Monte Carlo}
\label{chap:mcmc}
Our goal to generate $M\in_R\mathcal{M}(\mathcal{P})$ heavily depends on the theory of Markov chains. We only define useful terms and state two important theorems. If you are interested in more details, see \cite{Madras}.

\section{Markov chains}
\begin{defn}
%We shall consider discrete-time \emph{Markov chain} $X_0,X_l,\dots$, where $X_i\in\mathcal{S}$, for a finite state space $\mathcal{S}$ and every $i$ (number of steps). The $k$-step transition probabilities are:
%$$p_{i,j}^{(k)}=Pr(X_{t+k}=j|X_t=i) \hspace{1cm} (i,j\in\mathcal{S})$$
Let $\mathcal{S}$ be a finite set of states and for every $i,j\in\mathcal{S}$ $p_{i,j}$ prescribed probability of a change of state from $i$ to $j$. Also let $X_0$ be a random variable with values from $\mathcal{S}$. We call a sequence $X_0,X_l,\dots$, where $X_i\in\mathcal{S}$ for every $i$ a \emph{Markov chain} if
$$Pr(X_{t+1}=j|X_t=i)=p_{i,j} \hspace{1cm} (i,j\in\mathcal{S})$$
\end{defn}
\begin{defn}
%A Markov chain is said to be \emph{symmetric} if $p_{i,j}^{(1)}=p_{j,i}^{(1)}$ for every pair of states $i$ and $j$.
A Markov chain is said to be \emph{symmetric} if $p_{i,j}=p_{j,i}$ for every pair of states $i$ and $j$.
\end{defn}
\begin{defn}
%A Markov chain is \emph{irreducible} if the chain can eventually get from each state to every other state, that is, for every $i,j\in\mathcal{S}$ there exists a $k\geq0$ (depending on $i$ and $j$) such that $p_{i,j}^{(k)}>0$.
A Markov chain is \emph{irreducible} if the chain can eventually get from each state to every other state, that is, for every $i,j\in\mathcal{S}$ there exists a $k\geq0$ (depending on $i$ and $j$) such that $Pr(X_k=j|X_0=i)>0$.
\end{defn}
\begin{defn}
%An irreducible chain has \emph{period} $D$ if $D$ is the greatest common divisor of $\{k\geq1|p_{i,i}^{(k)}>0\}$ for some $i\in\mathcal{S}$ (equivalently, for all $i\in S$). A chain is called \emph{aperiodic} if its period is 1. In particular, if an irreducible chain has $p_{i,i}^{(1)}>0$ for some $i$, then it is aperiodic.
If an irreducible chain has $p_{i,i}>0$ for some $i$, then it is \emph{aperiodic}.
\end{defn}
Let $p_{i,j}^{(k)}=Pr(X_{t+k}=j|X_t=i)$ denote the $k$-step transition probabilities for $k=0,1,\cdots$ and $i,j\in\mathcal{S}$. The transition probability matrix is $P=(p_{i,j})$.

Next we state two theorems allowing us to expect Markov chains to converge to a uniformly random state in $\mathcal{S}$ even if the initial state $X_0$ is not random. Both theorems can be found in \cite{Madras}.
\begin{thm}
Consider an aperiodic irreducible Markov chain with finite state space $\mathcal{S}$. For every $i,j\in S$, the limit $\lim_{k\rightarrow\infty}p_{i,j}^{(k)}$ exists and is independent of $i$; call it $\pi_j$. Furthermore, $$\sum\limits_{j\in\mathcal{S}}\pi_j=1\hspace{5mm}\wedge\hspace{5mm}\sum\limits_{i\in\mathcal{S}}\pi_ip_{i,j}^{(1)}=\pi_j$$
for every $j\in\mathcal{S}$.
\end{thm}
\begin{thm}
Suppose that an irreducible Markov chain on the finite state space $\mathcal{S}$ is symmetric. Then the equilibrium distribution is uniform on $\mathcal{S}$.
\end{thm}

\section{Markov chain for pattern-avoiding binary matrices}
\label{sect:mmcmc}
To generate a binary matrix $M\in\{0,1\}^{n\times n}$ avoiding patterns in $\mathcal{P}$, we create a Markov chain, whose states space is $\mathcal{M}_n(\mathcal{P})$. After sufficiently many iterations ($m$) of MCMC process we set $M:=X_m\in\mathcal{M}_n(\mathcal{P})$. We always begin with an initial matrix $X_0$ and the process looks like this:
\begin{enumerate}
\item For $i:=1,2,\cdots,m$:
\item \hspace{5mm} Set $X_{i}:=X_{i-1}$.
\item \hspace{5mm} Choose $r\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Choose $c\in_R\{0,1,\cdots,n-1\}$ uniformly at random.
\item \hspace{5mm} Flip the bit at $X_{i}[r,c]$.
\item \hspace{5mm} If $X_{i}$ contains $\mathcal{P}$, flip the bit back.
\end{enumerate}

If the process starts with a matrix $X_0$ that avoids $\mathcal{P}$, then after every step it still avoids $\mathcal{P}$. Note that an iteration does not change the matrix if the condition 6 is satisfied. We need to show the Markov chain we presented meets all the conditions of both theorems:
\subsubsection{Symmetry}
Imagine a sequence of bits flipping that changes the $i$-th matrix to the $j$-th one. The reversed order of the same sequence changes the $j$-th matrix to the $i$-th one.
\subsubsection{Irreducibility}
As the steps go, it is easy to see we can with non-zero probability create any matrix $M_1\in\mathcal{M}_n(\mathcal{P})$ from the zero matrix $0_n=0^{n\times n}$ by choosing the one-entries of $M_1$. When we can get from $0_n$ to $M_2$ by a sequence of flip changes, the reversed sequence is a sequence of steps from $M_2\in\mathcal{M}_n(\mathcal{P})$ to $0_n$. Thus, with non-zero probability we can always reach $M_2$ from $M_1$; therefore, the Markov chain is irreducible.
\subsubsection{Aperiodicity}
The Markov chain is irreducible so it suffices to show that there is an $i$ for which $p_{i,i}>0$. Clearly, there is a matrix for which there is at least one bit that cannot be flipped without creating a pattern (for example the one with the maximum number of one-entries) and this forces $p_{i,i}>0$.