\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
We have seen, how to use Markov chain Monte Carlo method to approximate a random matrix of given size avoiding a given set of forbidden patterns. We have used a heavily improved brute force algorithm to test avoidance of a general pattern and a simple dynamic programming algorithm for testing avoidance of a pattern, where all one-entries are contained on a walk in the pattern. To even more improve performance of the program, we have used parallel computing in the layer of the MCMC process.

The question is, whether we can do better? We probably cannot asymptotically improve the walking pattern avoidance algorithm (more in Chapter \ref{chap:walking}), because it is already linear in the number of elements of the matrix and computes only those elements that have changed. On the other hand, the algorithm is only useful for a small portion of all possible patterns. A natural question is, whether we can do as good for other classes of matrices?

In Section \ref{wholestructure}, we mentioned an alternative algorithm for testing avoidance of general patterns. Although it is probably not a very good algorithm for big matrices, because it needs to store all possible partial mappings, it may still turn out to be much better for smaller matrices, which are still big enough to see a structure in them, than the implemented algorithm is.

To use parallelism, we decided to use the MCMC layer of the program. There were several reasons to do so. First of all, it is not dependent on the avoidance pattern algorithm; therefore, if someone comes with a better one, it can still use the parallel version of MCMC. Secondly, when the matrix gets complex enough, the probability a change of one element is going to be successful is very small; thus, we have chosen to iterate through unsuccessful changes faster over the possibility to test avoidance faster.

A different approach would be to make avoidance testing parallel. In walking pattern, we could recompute multiple elements of the same diagonal at once, because they do not influence each other. In the algorithm for general patterns, we could generate new partial mappings in parallel, since they are independent. The only problem there is deciding whether two mappings are equivalent.